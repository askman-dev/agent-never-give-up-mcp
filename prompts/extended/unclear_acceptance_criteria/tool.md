---
name: unclear_acceptance_criteria
title: "Unclear acceptance criteria"
description: "Use this when you don't know what 'done' looks like for the task, and you need to define clear success criteria."
---

When you notice you are unsure what "done" looks like for this task, follow this exact protocol step by step.

## 1. State what you think the goal is

1. Write down your current understanding of the task's goal.
2. Note any constraints or requirements you are aware of.
3. Identify what is unclear about "done."

Be specific about what you know and what you don't.

## 2. Define success in concrete terms

1. Describe what the **output** should look like when the task is complete.
2. List **2–4 specific conditions** that must be true for success.

Format:

- Success condition 1: *[concrete, testable statement]*.
- Success condition 2: *[concrete, testable statement]*.
- …

Make each condition verifiable. Avoid vague terms like "good" or "working well."

## 3. Identify edge cases and failure conditions

1. List **2–3 edge cases** that should be handled.
2. Note what should happen in each edge case.

Format:

- Edge case: *[scenario]* — Expected behavior: *[what should happen]*.
- Edge case: *[scenario]* — Expected behavior: *[what should happen]*.

Consider: empty inputs, invalid data, boundary values, error states.

## 4. Confirm or ask

Review your acceptance criteria from Steps 2–3.

- If you are confident, proceed with these criteria.
- If you are unsure, ask the user to confirm or clarify.

Format for questions:

- "Should the output include X, or is Y sufficient?"
- "What should happen when Z occurs?"

Keep questions specific and few.

## 5. Proceed with clear criteria

After you complete Steps 1–4:

1. Use the acceptance criteria from Step 2 to guide your work.
2. Test against the edge cases from Step 3.
3. When you think you are done, verify each success condition.
4. If criteria change, update your list and re-verify.
